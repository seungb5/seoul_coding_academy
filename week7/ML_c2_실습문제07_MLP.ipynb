{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mglearn\n",
    "from sklearn.base import clone\n",
    "from matplotlib import font_manager\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "# font_name = font_manager.FontProperties(fname=\"NanumBarunGothic.ttf\").get_name()\n",
    "plt.rc('font', family=font_name)\n",
    "plt.rcParams[\"font.family\"] = font_name\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 07\n",
    "- 유방암 데이터를 이용하여, MLPClassifier를 이용하여 테스트 성능을 향상시키자.\n",
    "- 3개의 은닉층을 갖고, 각 은닉층의 유닛수는 100개를 넘지 않도록 하여, 튜닝해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.92\n",
      "테스트 세트 정확도: 0.92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0. 데이터 불러오기\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# 1. 데이터 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "# 2. 표준화 전처리 \n",
    "# 훈련 세트 각 특성의 평균을 계산합니다\n",
    "mean_on_train = X_train.mean(axis=0)\n",
    "# 훈련 세트 각 특성의 표준 편차를 계산합니다\n",
    "std_on_train = X_train.std(axis=0)\n",
    "\n",
    "# 데이터에서 평균을 빼고 표준 편차로 나누면\n",
    "# 평균 0, 표준 편차 1 인 데이터로 변환됩니다.\n",
    "X_train_scaled = (X_train - mean_on_train) / std_on_train\n",
    "# (훈련 데이터의 평균과 표준 편차를 이용해) 같은 변환을 테스트 세트에도 합니다\n",
    "X_test_scaled = (X_test - mean_on_train) / std_on_train\n",
    "\n",
    "# 3. base 모델 \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 50, 25), max_iter=2000)\n",
    "mlp.fit(X_train, y_train)\n",
    "print(\"훈련 세트 정확도: {:.2f}\".format(mlp.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.2f}\\n\".format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100, 50, 25), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "\n",
      "훈련 세트 정확도: 0.97\n",
      "테스트 세트 정확도: 0.95\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100, 50, 25), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "\n",
      "훈련 세트 정확도: 0.95\n",
      "테스트 세트 정확도: 0.95\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100, 50, 25), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "\n",
      "훈련 세트 정확도: 0.97\n",
      "테스트 세트 정확도: 0.95\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100, 50, 25), learning_rate='invscaling',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "\n",
      "훈련 세트 정확도: 0.97\n",
      "테스트 세트 정확도: 0.96\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100, 50, 25), learning_rate='invscaling',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "\n",
      "훈련 세트 정확도: 0.92\n",
      "테스트 세트 정확도: 0.94\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100, 50, 25), learning_rate='invscaling',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "\n",
      "훈련 세트 정확도: 0.97\n",
      "테스트 세트 정확도: 0.94\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100, 50, 25), learning_rate='invscaling',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "\n",
      "훈련 세트 정확도: 0.99\n",
      "테스트 세트 정확도: 0.95\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100, 50, 25), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "\n",
      "훈련 세트 정확도: 0.99\n",
      "테스트 세트 정확도: 0.96\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100, 50, 25), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "\n",
      "훈련 세트 정확도: 0.99\n",
      "테스트 세트 정확도: 0.95\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100, 50, 25), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "\n",
      "훈련 세트 정확도: 0.93\n",
      "테스트 세트 정확도: 0.94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. model 튜닝\n",
    "learning_rate = ['constant', 'invscaling', 'adaptive']\n",
    "alpha = [0.01, 0.1, 1, 10]\n",
    "solver = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "for lr in learning_rate:\n",
    "    for a in alpha:\n",
    "        for sol in solver:\n",
    "            mlp.set_params(learning_rate = lr, alpha = a, solver=sol)\n",
    "            mlp.fit(X_train, y_train)\n",
    "            if mlp.score(X_test, y_test) > .94:\n",
    "                print(\"{}\\n\".format(mlp))\n",
    "                print(\"훈련 세트 정확도: {:.2f}\".format(mlp.score(X_train, y_train)))\n",
    "                print(\"테스트 세트 정확도: {:.2f}\\n\".format(mlp.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
